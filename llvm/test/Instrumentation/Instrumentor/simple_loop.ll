; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt < %s -passes=instrumentor -S | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128"

; Function Attrs: nofree nosync nounwind uwtable
define dso_local double @foo(i64 noundef %j, i64 noundef %N) local_unnamed_addr #0 {
; CHECK-LABEL: define dso_local double @foo(
; CHECK-SAME: i64 noundef [[J:%.*]], i64 noundef [[N:%.*]]) local_unnamed_addr {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.stacksave.p0()
; CHECK-NEXT:    [[VLA:%.*]] = alloca double, i64 [[N]], align 16
; CHECK-NEXT:    [[TMP1:%.*]] = mul i64 8, [[N]]
; CHECK-NEXT:    [[TMP2:%.*]] = call ptr @__instrumentor_post_alloca(ptr [[VLA]], i64 [[TMP1]], i64 16)
; CHECK-NEXT:    [[CMP5:%.*]] = icmp sgt i64 [[N]], 0
; CHECK-NEXT:    br i1 [[CMP5]], label %[[FOR_BODY_PREHEADER:.*]], label %[[FOR_COND_CLEANUP:.*]]
; CHECK:       [[FOR_BODY_PREHEADER]]:
; CHECK-NEXT:    [[XTRAITER:%.*]] = and i64 [[N]], 3
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[N]], 4
; CHECK-NEXT:    br i1 [[TMP3]], label %[[FOR_COND_CLEANUP_LOOPEXIT_UNR_LCSSA:.*]], label %[[FOR_BODY_PREHEADER_NEW:.*]]
; CHECK:       [[FOR_BODY_PREHEADER_NEW]]:
; CHECK-NEXT:    [[UNROLL_ITER:%.*]] = and i64 [[N]], -4
; CHECK-NEXT:    br label %[[FOR_BODY:.*]]
; CHECK:       [[FOR_COND_CLEANUP_LOOPEXIT_UNR_LCSSA]]:
; CHECK-NEXT:    [[I_06_UNR:%.*]] = phi i64 [ 0, %[[FOR_BODY_PREHEADER]] ], [ [[INC_3:%.*]], %[[FOR_BODY]] ]
; CHECK-NEXT:    [[LCMP_MOD_NOT:%.*]] = icmp eq i64 [[XTRAITER]], 0
; CHECK-NEXT:    br i1 [[LCMP_MOD_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY_EPIL:.*]]
; CHECK:       [[FOR_BODY_EPIL]]:
; CHECK-NEXT:    [[I_06_EPIL:%.*]] = phi i64 [ [[INC_EPIL:%.*]], %[[FOR_BODY_EPIL]] ], [ [[I_06_UNR]], %[[FOR_COND_CLEANUP_LOOPEXIT_UNR_LCSSA]] ]
; CHECK-NEXT:    [[EPIL_ITER:%.*]] = phi i64 [ [[EPIL_ITER_NEXT:%.*]], %[[FOR_BODY_EPIL]] ], [ 0, %[[FOR_COND_CLEANUP_LOOPEXIT_UNR_LCSSA]] ]
; CHECK-NEXT:    [[CONV_EPIL:%.*]] = sitofp i64 [[I_06_EPIL]] to double
; CHECK-NEXT:    [[MUL_EPIL:%.*]] = fmul double [[CONV_EPIL]], 3.140000e+00
; CHECK-NEXT:    [[ARRAYIDX_EPIL:%.*]] = getelementptr inbounds double, ptr [[TMP2]], i64 [[I_06_EPIL]]
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast double [[MUL_EPIL]] to i64
; CHECK-NEXT:    [[TMP12:%.*]] = call ptr @__instrumentor_pre_store(ptr [[ARRAYIDX_EPIL]], i32 0, i64 [[TMP4]], i64 64, i32 3, i64 8, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    store double [[MUL_EPIL]], ptr [[TMP12]], align 8
; CHECK-NEXT:    [[INC_EPIL]] = add nuw nsw i64 [[I_06_EPIL]], 1
; CHECK-NEXT:    [[EPIL_ITER_NEXT]] = add i64 [[EPIL_ITER]], 1
; CHECK-NEXT:    [[EPIL_ITER_CMP_NOT:%.*]] = icmp eq i64 [[EPIL_ITER_NEXT]], [[XTRAITER]]
; CHECK-NEXT:    br i1 [[EPIL_ITER_CMP_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY_EPIL]]
; CHECK:       [[FOR_COND_CLEANUP]]:
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds double, ptr [[TMP2]], i64 [[J]]
; CHECK-NEXT:    [[TMP14:%.*]] = call ptr @__instrumentor_pre_load(ptr [[ARRAYIDX1]], i32 0, i64 8, i32 3, i64 8, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    [[TMP5:%.*]] = load double, ptr [[TMP14]], align 8
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast double [[TMP5]] to i64
; CHECK-NEXT:    [[TMP18:%.*]] = call i64 @__instrumentor_post_load(ptr [[TMP14]], i32 0, i64 [[TMP10]], i64 8, i32 3, i64 8, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i64 [[TMP18]] to double
; CHECK-NEXT:    tail call void @llvm.stackrestore.p0(ptr [[TMP0]])
; CHECK-NEXT:    ret double [[TMP19]]
; CHECK:       [[FOR_BODY]]:
; CHECK-NEXT:    [[I_06:%.*]] = phi i64 [ 0, %[[FOR_BODY_PREHEADER_NEW]] ], [ [[INC_3]], %[[FOR_BODY]] ]
; CHECK-NEXT:    [[NITER:%.*]] = phi i64 [ 0, %[[FOR_BODY_PREHEADER_NEW]] ], [ [[NITER_NEXT_3:%.*]], %[[FOR_BODY]] ]
; CHECK-NEXT:    [[CONV:%.*]] = sitofp i64 [[I_06]] to double
; CHECK-NEXT:    [[MUL:%.*]] = fmul double [[CONV]], 3.140000e+00
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds double, ptr [[TMP2]], i64 [[I_06]]
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast double [[MUL]] to i64
; CHECK-NEXT:    [[TMP11:%.*]] = call ptr @__instrumentor_pre_store(ptr [[ARRAYIDX]], i32 0, i64 [[TMP6]], i64 64, i32 3, i64 16, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    store double [[MUL]], ptr [[TMP11]], align 16
; CHECK-NEXT:    [[INC:%.*]] = or i64 [[I_06]], 1
; CHECK-NEXT:    [[CONV_1:%.*]] = sitofp i64 [[INC]] to double
; CHECK-NEXT:    [[MUL_1:%.*]] = fmul double [[CONV_1]], 3.140000e+00
; CHECK-NEXT:    [[ARRAYIDX_1:%.*]] = getelementptr inbounds double, ptr [[TMP2]], i64 [[INC]]
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast double [[MUL_1]] to i64
; CHECK-NEXT:    [[TMP13:%.*]] = call ptr @__instrumentor_pre_store(ptr [[ARRAYIDX_1]], i32 0, i64 [[TMP7]], i64 64, i32 3, i64 8, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    store double [[MUL_1]], ptr [[TMP13]], align 8
; CHECK-NEXT:    [[INC_1:%.*]] = or i64 [[I_06]], 2
; CHECK-NEXT:    [[CONV_2:%.*]] = sitofp i64 [[INC_1]] to double
; CHECK-NEXT:    [[MUL_2:%.*]] = fmul double [[CONV_2]], 3.140000e+00
; CHECK-NEXT:    [[ARRAYIDX_2:%.*]] = getelementptr inbounds double, ptr [[TMP2]], i64 [[INC_1]]
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast double [[MUL_2]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = call ptr @__instrumentor_pre_store(ptr [[ARRAYIDX_2]], i32 0, i64 [[TMP8]], i64 64, i32 3, i64 16, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    store double [[MUL_2]], ptr [[TMP15]], align 16
; CHECK-NEXT:    [[INC_2:%.*]] = or i64 [[I_06]], 3
; CHECK-NEXT:    [[CONV_3:%.*]] = sitofp i64 [[INC_2]] to double
; CHECK-NEXT:    [[MUL_3:%.*]] = fmul double [[CONV_3]], 3.140000e+00
; CHECK-NEXT:    [[ARRAYIDX_3:%.*]] = getelementptr inbounds double, ptr [[TMP2]], i64 [[INC_2]]
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast double [[MUL_3]] to i64
; CHECK-NEXT:    [[TMP17:%.*]] = call ptr @__instrumentor_pre_store(ptr [[ARRAYIDX_3]], i32 0, i64 [[TMP9]], i64 64, i32 3, i64 8, i32 0, i8 1, i8 0, ptr null)
; CHECK-NEXT:    store double [[MUL_3]], ptr [[TMP17]], align 8
; CHECK-NEXT:    [[INC_3]] = add nuw nsw i64 [[I_06]], 4
; CHECK-NEXT:    [[NITER_NEXT_3]] = add i64 [[NITER]], 4
; CHECK-NEXT:    [[NITER_NCMP_3:%.*]] = icmp eq i64 [[NITER_NEXT_3]], [[UNROLL_ITER]]
; CHECK-NEXT:    br i1 [[NITER_NCMP_3]], label %[[FOR_COND_CLEANUP_LOOPEXIT_UNR_LCSSA]], label %[[FOR_BODY]]
;
entry:
  %0 = tail call ptr @llvm.stacksave.p0()
  %vla = alloca double, i64 %N, align 16
  %cmp5 = icmp sgt i64 %N, 0
  br i1 %cmp5, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %entry
  %xtraiter = and i64 %N, 3
  %1 = icmp ult i64 %N, 4
  br i1 %1, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.body.preheader.new

for.body.preheader.new:                           ; preds = %for.body.preheader
  %unroll_iter = and i64 %N, -4
  br label %for.body

for.cond.cleanup.loopexit.unr-lcssa:              ; preds = %for.body, %for.body.preheader
  %i.06.unr = phi i64 [ 0, %for.body.preheader ], [ %inc.3, %for.body ]
  %lcmp.mod.not = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod.not, label %for.cond.cleanup, label %for.body.epil

for.body.epil:                                    ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %for.body.epil
  %i.06.epil = phi i64 [ %inc.epil, %for.body.epil ], [ %i.06.unr, %for.cond.cleanup.loopexit.unr-lcssa ]
  %epil.iter = phi i64 [ %epil.iter.next, %for.body.epil ], [ 0, %for.cond.cleanup.loopexit.unr-lcssa ]
  %conv.epil = sitofp i64 %i.06.epil to double
  %mul.epil = fmul double %conv.epil, 3.140000e+00
  %arrayidx.epil = getelementptr inbounds double, ptr %vla, i64 %i.06.epil
  store double %mul.epil, ptr %arrayidx.epil, align 8
  %inc.epil = add nuw nsw i64 %i.06.epil, 1
  %epil.iter.next = add i64 %epil.iter, 1
  %epil.iter.cmp.not = icmp eq i64 %epil.iter.next, %xtraiter
  br i1 %epil.iter.cmp.not, label %for.cond.cleanup, label %for.body.epil

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %for.body.epil, %entry
  %arrayidx1 = getelementptr inbounds double, ptr %vla, i64 %j
  %2 = load double, ptr %arrayidx1, align 8
  tail call void @llvm.stackrestore.p0(ptr %0)
  ret double %2

for.body:                                         ; preds = %for.body, %for.body.preheader.new
  %i.06 = phi i64 [ 0, %for.body.preheader.new ], [ %inc.3, %for.body ]
  %niter = phi i64 [ 0, %for.body.preheader.new ], [ %niter.next.3, %for.body ]
  %conv = sitofp i64 %i.06 to double
  %mul = fmul double %conv, 3.140000e+00
  %arrayidx = getelementptr inbounds double, ptr %vla, i64 %i.06
  store double %mul, ptr %arrayidx, align 16
  %inc = or i64 %i.06, 1
  %conv.1 = sitofp i64 %inc to double
  %mul.1 = fmul double %conv.1, 3.140000e+00
  %arrayidx.1 = getelementptr inbounds double, ptr %vla, i64 %inc
  store double %mul.1, ptr %arrayidx.1, align 8
  %inc.1 = or i64 %i.06, 2
  %conv.2 = sitofp i64 %inc.1 to double
  %mul.2 = fmul double %conv.2, 3.140000e+00
  %arrayidx.2 = getelementptr inbounds double, ptr %vla, i64 %inc.1
  store double %mul.2, ptr %arrayidx.2, align 16
  %inc.2 = or i64 %i.06, 3
  %conv.3 = sitofp i64 %inc.2 to double
  %mul.3 = fmul double %conv.3, 3.140000e+00
  %arrayidx.3 = getelementptr inbounds double, ptr %vla, i64 %inc.2
  store double %mul.3, ptr %arrayidx.3, align 8
  %inc.3 = add nuw nsw i64 %i.06, 4
  %niter.next.3 = add i64 %niter, 4
  %niter.ncmp.3 = icmp eq i64 %niter.next.3, %unroll_iter
  br i1 %niter.ncmp.3, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.body
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare ptr @llvm.stacksave.p0() #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn
declare void @llvm.stackrestore.p0(ptr) #1

